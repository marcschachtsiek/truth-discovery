{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['n_sources', 'n_dataitems', 'n_distinct', 'algorithms_info', 'experiments'])\n",
      "dict_keys(['coverage_dist', 'truth_dist', 'distinct_dist', 'spread_dist', 'optimal', 'n_claims', 'iteration_index', 'results'])\n",
      "{'name': 'TruncExponential', 'lmbda': 0.5, 'flipped': True}\n",
      "{'time': 0.038550333999999964, 'scores': [1.0, 200]}\n"
     ]
    }
   ],
   "source": [
    "results.keys()\n",
    "experiments = results['experiments']\n",
    "\n",
    "algorithms = {}\n",
    "for algo in results['algorithms_info']:\n",
    "    algorithms[algo['name']] = algo\n",
    "\n",
    "print(results.keys())\n",
    "\n",
    "print(experiments[0].keys())\n",
    "\n",
    "print(experiments[0]['coverage_dist'])\n",
    "print(experiments[0]['results']['Majority'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_dataframe(exp_name, in_parts, postfix_list=None, folder=None, return_optional=False):\n",
    "    \n",
    "    rows = []\n",
    "    index = 0\n",
    "    \n",
    "    n_parts = 7 if in_parts else 1\n",
    "    if postfix_list is not None and len(postfix_list) != n_parts:\n",
    "        raise ValueError(\"Length of postfix list must match number of parts\")\n",
    "        \n",
    "    for i in range(n_parts):\n",
    "        if postfix_list is not None:\n",
    "            pf_list = ['', postfix_list[i]]\n",
    "        else:\n",
    "            pf_list = ['']\n",
    "\n",
    "        for postfix in pf_list:\n",
    "        \n",
    "            name = f\"{exp_name}-part{i}\" if in_parts else exp_name\n",
    "            if folder is None:\n",
    "                path = os.path.join(\"results\", name + postfix + \".json\")\n",
    "            else:\n",
    "                path = os.path.join(\"results\", folder, name + postfix + \".json\")\n",
    "\n",
    "            with open(path, \"r\") as f:\n",
    "                results = json.load(f)\n",
    "                \n",
    "            dictionary = {\n",
    "                'n_sources': results['n_sources'],\n",
    "                'n_dataitems': results['n_dataitems'],\n",
    "                'n_distinct': results['n_distinct'],\n",
    "            }\n",
    "\n",
    "            algorithms = {}\n",
    "            for algo in results['algorithms_info']:\n",
    "                algorithms[algo['name']] = algo\n",
    "\n",
    "            for experiment in results['experiments']:\n",
    "                for dist in ['coverage_dist', 'truth_dist', 'distinct_dist', 'spread_dist']:\n",
    "                    prefix = \"\"\n",
    "                    if 'flipped' in experiment[dist] and experiment[dist]['flipped']:\n",
    "                        prefix += \"F_\"\n",
    "                    if experiment[dist]['name'] == 'TruncExponential' and experiment[dist]['lmbda'] == 0.5:\n",
    "                        prefix += \"H_\"\n",
    "                    dictionary[dist] = prefix + experiment[dist]['name']\n",
    "\n",
    "                dictionary['optimal_perc_score'] = experiment['optimal'][0]\n",
    "                dictionary['optimal_score'] = experiment['optimal'][1]\n",
    "                dictionary['n_claims'] = experiment['n_claims']\n",
    "                dictionary['iteration_index'] = experiment['iteration_index'] if 'iteration_index' in experiment else -1\n",
    "\n",
    "                for key, value in experiment['results'].items():\n",
    "                    dictionary[f'{key}_time'] = value['time']\n",
    "                    dictionary[f'{key}_score_perc'] = value['scores'][0]\n",
    "                    dictionary[f'{key}_score'] = value['scores'][1]\n",
    "                \n",
    "                rows.append(pd.DataFrame.from_dict({index: dictionary}, orient='index'))\n",
    "                index += 1\n",
    "        \n",
    "    if return_optional:\n",
    "        return pd.concat(rows), algorithms\n",
    "    \n",
    "    return pd.concat(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"run3-200-200-20\"\n",
    "df = results_to_dataframe(exp_name, in_parts=True, folder=exp_name)\n",
    "df.to_csv(os.path.join(\"results\", f\"{exp_name}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2401, 23)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
